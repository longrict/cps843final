\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{float}

\begin{document}

\title{Real-Time Traffic Signal Detection for Live Video Streams Using YOLOv8}

\author{
\IEEEauthorblockN{Hareesh Suresh, Longric Tran, Sheel Patel}
\IEEEauthorblockA{Department of Computer Science\\
Toronto Metropolitan University\\
Toronto, Ontario, Canada\\
hsuresh@torontomu.ca, longric.tran@torontomu.ca, s60patel@torontomu.ca}
}

\maketitle

%==============================================================================
% ABSTRACT
%==============================================================================
\begin{abstract}
This project aims to build a real-time traffic sign detection system by fine-tuning a pre-existing YOLOv8 model. The goal is to detect and classify traffic signs in live video
while keeping latency low enough for practical use. To achieve our goal, a pre-trained YOLOv8 model was retrained on a traffic signs dataset with fifteen  
labels for various signals, and regulatory signs. The system runs through a simple pipeline that includes training, testing, and real 
time detection via webcam using OpenCV. Our results show that YOLOv8 works well for this task, achieving solid detection accuracy while maintaining reasonable
detection speed.

\vspace{0.5em}
\noindent\textbf{Source Code:} \url{https://github.com/longrict/cps843final/}
\end{abstract}

%==============================================================================
% INTRODUCTION
%==============================================================================
\section{Introduction}

Traffic and regulatory signs have the important role of quickly and effectively communicating rules and warnings to drivers across the world. As demand for self-driving cars, 
and driver assistance systems grows, the need for automatic detection and classification systems becomes clear. The main challenges in developing such products however, relates to
balancing the accuracy of the predictions and the speed at which detections can be made. Such systems must also function under different environmental conditions including changes in
lighting, occlusion and weather. 

Many approaches have been created to approach this problem. Many early methods relied heavily on domain knowledge and hand crafted features, but were not robust and would struggle under varying 
environmental conditions. A newer approach through the usage of deep learning and Convolutional Neural Networks (CNN), which learn directly from the data rather than from human intervention, offers
significantly improved robustness and accuracy enabling models to better generalize to varying signs and conditions.

One popular approach uses a CNN-based framework called You Only Look Once (YOLO) for object detection.
Unlike other detectors that look at an image multiple times, YOLO processes the whole image in one pass, significantly improving speeds and enabling its usage for real-time detection.

For this project YOLOv8, a YOLO-style developed by Ultralytics, was chosen as a base object detection framework.

The project is composed of three main parts:
1. Model training on a traffic data set.
2. Validation on a test set of still images to measure accuracy.
3. Live tests on a webcam through the usage of OpenCV.

%==============================================================================
% TECHNICAL PART
%==============================================================================
\section{Technical Approach}

\subsection{Why YOLOv8?}

We picked YOLOv8 for a few reasons. First, it's fast. Since no one in our group had the latest Nvidia GPU, we wanted something lightweight and easy to train and tweak, while still being fast enough to process video frames in real time without significant lag. Second, it's accurate, especially for small objects, and significantly more accurate than the results we got when testing with the CNN model we initially started with. Lastly, the Ultralytics library makes it easy to use. You can train, test, and deploy a model with just a few lines of Python code, keeping code simple and easy to understand and modify for future iterations.

\subsection{How YOLOv8 Works}

YOLOv8 has three main parts:

The architecture has three main parts: the \textbf{backbone}, \textbf{neck}, and \textbf{head}. The backbone is a pre trained convolutional neural network (CNN) that extracts features from the input image at different levels. The neck merges these features together using something called a Feature Pyramid Network (FPN), which helps the model detect objects of different sizes. Finally, the head takes these combined features and outputs the final predictions, including bounding boxes and class labels \cite{viso_yolov8}.

What makes YOLOv8 stand out from earlier versions are a few key improvements. It uses a decoupled head, which separates classification and localization into different branches so each can focus on its own task. It also uses anchor free detection, meaning it doesn't rely on predefined box shapes to make predictions. YOLOv8 also uses mosaic data augmentation during training, which combines four images into one to help the model learn from more varied examples \cite{viso_yolov8}.

\subsection{Training Process}

The training configuration was kept simple. We trained for 50 epochs with an image size of 416 pixels and a batch size of 16. The dataset configuration was stored in a YAML file (trafficsigns.yaml), which told the model where to find the training and validation images and what classes to look for. Training was done on a GPU to speed things up.

During training, YOLOv8 applies mosaic data augmentation, which combines four training images into one. This exposes the model to more varied object arrangements and scales in each batch, helping it generalize better to real world conditions. The augmentation is automatically turned off in the last ten epochs to let the model fine tune on cleaner examples \cite{viso_yolov8}.

Using a pre trained model as a starting point saved us a lot of time. Instead of learning from scratch, the model already understood basic visual features like edges, shapes, and textures. We only needed to teach the differences between a stop sign and a speed limit sign. This approach is called transfer learning, and it typically gives better results than training a model from nothing, especially when working with a smaller dataset \cite{viso_yolov8}.

\subsection{Real-Time Detection}

TODO: This section needs to be done
%==============================================================================
% EXPERIMENTS
%==============================================================================
\section{Experiments}

\subsection{Dataset}

We used the Traffic Signs Detection dataset from Kaggle, created by P.K. Darabi. The dataset is formatted for YOLO, with each image having a corresponding annotation file. The annotations follow the standard YOLO format:
\begin{verbatim}
    [class_id] [center_x] [center_y] 
            [width] [height]
\end{verbatim}
The coordinates are normalized (values between 0 and 1), which makes them work regardless of image size. Images in the dataset are 416x416 pixels with 3 color channels.
The dataset contains 15 classes focused on speed limits, traffic lights, and stop signs:
\begin{table}[h]
\centering
\caption{Traffic Sign Classes in Dataset}
\label{tab:categories}
\begin{tabular}{ll}
\toprule
\textbf{Category} & \textbf{Classes} \\
\midrule
Traffic Lights & Green Light, Red Light \\
Speed Limits & 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120 km/h \\
Regulatory & Stop \\
\bottomrule
\end{tabular}
\end{table}
The dataset was split into three sets: 3,530 images for training, 801 images for validation, and a separate test set for final evaluation.
Before training our own model, we tested the default pre trained YOLOv8 model on the dataset to see how it would perform. Since the default model was trained on general objects (the COCO dataset), it returned no detections when given a traffic sign image. This confirmed that we needed to fine tune the model on our specific dataset to get it to recognize traffic signs \cite{kaggle_dataset}.

\subsection{Training Setup}

TODO: This section needs to be completed

\subsection{Evaluation Metrics}

TODO: Need to look at the code to understand how it works

\subsection{Results}

TODO: What are the result i don't really know what to say here




\subsection{Real Time Performance}

After training, which took some time as the model adjusted and optimized the weights for each class, the test script ran smoothly. The model was able to predict stop signs and other traffic signs with around 70 to 80 percent accuracy. When running real time detection using the laptop's webcam, the system performed smoothly with minimal lag, making it responsive enough for practical use. Testing was done on a standard laptop without a dedicated GPU, which shows that YOLOv8's nano version is lightweight enough for everyday hardware.

\subsection{What Worked and What Didn't}

\textbf{What worked well:}
\begin{itemize}
    \item Regulatory signs (like stop signs) were detected reliably. They have distinctive shapes and colours, and were spotted from various angles.
    \item TODO:add the other things that work. I was only able to test it with a stop sign 
\end{itemize}

\textbf{Challenges we encountered:}
\begin{itemize}
    \item Signs that are very far away (small in the image) are harder to detect.
    \item Signs displayed on a phone screen were difficult to detect. Only the stop sign was recognized reliably, and only when held directly facing the camera.
\end{itemize}

%==============================================================================
% CONCLUSION
%==============================================================================
\section{Conclusion}

TODO:Conclusion need to be added here  


%==============================================================================
% REFERENCES
%==============================================================================
\begin{thebibliography}{00}

\bibitem{kaggle_dataset}
P. K. Darabi, ``Traffic Signs Detection Using YOLOv8,'' Kaggle, 2023. [Online]. Available: \url{https://www.kaggle.com/code/pkdarabi/traffic-signs-detection-using-yolov8}

\bibitem{viso_yolov8}
Viso.ai, ``YOLOv8: A Complete Guide,'' 2023. [Online]. Available: \url{https://viso.ai/deep-learning/yolov8-guide/}
\end{thebibliography}

\end{document}